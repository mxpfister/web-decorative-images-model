{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUo_2AjETxvY",
        "outputId": "1ce5c007-2229-4967-ef77-04bba7c2a10a"
      },
      "outputs": [],
      "source": [
        "!pip install mysql-connector-python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import tarfile\n",
        "import sqlite3\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization, Multiply, Add, Reshape, TextVectorization\n",
        "from tensorflow.keras.activations import sigmoid, tanh\n",
        "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "import mysql.connector\n",
        "from collections import defaultdict, Counter\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I-9yDVV9NeT",
        "outputId": "97e5c89e-0cc9-41c7-bc44-4183b722e26b"
      },
      "outputs": [],
      "source": [
        "connection = mysql.connector.connect(\n",
        "    host=\"\",\n",
        "    user=\"\",\n",
        "    password=\"\",\n",
        "    database=\"\"\n",
        ")\n",
        "\n",
        "cursor = connection.cursor(dictionary=True)\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    i.page_id,\n",
        "    i.hash,\n",
        "    i.file_name,\n",
        "    i.alt_text,\n",
        "    i.image_title,\n",
        "    i.image_caption,\n",
        "    i.width,\n",
        "    i.height,\n",
        "    i.contains_transparency,\n",
        "    i.wrapped_element,\n",
        "    i.semantic_context,\n",
        "    i.is_link,\n",
        "    i.is_button,\n",
        "    i.file_format,\n",
        "    i.is_decorative,\n",
        "    i.headline_above_image,\n",
        "    p.title,\n",
        "    p.meta_description,\n",
        "    p.top_headline,\n",
        "    p.word_count,\n",
        "    p.image_count,\n",
        "    p.external_link_count,\n",
        "    p.internal_link_count,\n",
        "    COUNT(*) AS context_frequency\n",
        "FROM\n",
        "    image i\n",
        "JOIN\n",
        "    page p ON i.page_id = p.id\n",
        "GROUP BY\n",
        "    i.hash,\n",
        "    i.alt_text,\n",
        "    i.image_title,\n",
        "    i.image_caption,\n",
        "    i.width,\n",
        "    i.height,\n",
        "    i.contains_transparency,\n",
        "    i.wrapped_element,\n",
        "    i.semantic_context,\n",
        "    i.headline_above_image,\n",
        "    i.is_link,\n",
        "    i.is_button,\n",
        "    i.file_format,\n",
        "    i.is_decorative;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "\n",
        "image_data = cursor.fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgsqXdntJrgV",
        "outputId": "3243f98a-3d85-41ff-cdd7-b6f46ce4335d"
      },
      "outputs": [],
      "source": [
        "dataset_url = \"\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, extract=False, force_download=True)\n",
        "\n",
        "gz_path = pathlib.Path(data_dir)\n",
        "tar_path = gz_path.with_suffix('')\n",
        "gz_path.rename(tar_path)\n",
        "\n",
        "with tarfile.open(tar_path, \"r\") as tar:\n",
        "    tar.extractall(path=tar_path.parent)\n",
        "\n",
        "all_images = list(tar_path.parent.glob('*.*'))\n",
        "image_count = len(all_images)\n",
        "print(\"Anzahl der Bilder:\", image_count)\n",
        "\n",
        "def load_image(file_name, target_size=(256, 256)):\n",
        "    image_path = tar_path.parent / file_name\n",
        "    if image_path.exists():\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        image = image.resize(target_size)\n",
        "        return image\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kskIn0STaaW"
      },
      "source": [
        "**PARAMETER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-6tUg6wTYB2"
      },
      "outputs": [],
      "source": [
        "image_height, image_width = 256, 256\n",
        "epochs = 15\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWkAGWEz8qG3"
      },
      "source": [
        "**DATA HANDLING & PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFB8FE-AKsMs"
      },
      "source": [
        "Step 1: aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkF2dAkia9La",
        "outputId": "6a01ef53-5c9f-43ae-f28b-bc872a70a0b7"
      },
      "outputs": [],
      "source": [
        "unique_hashes = np.unique([entry['hash'] for entry in image_data])\n",
        "aggregated_data = []\n",
        "\n",
        "for hash_value in unique_hashes:\n",
        "    entries_for_hash = [entry for entry in image_data if entry['hash'] == hash_value]\n",
        "\n",
        "    # aggregation of numeric values\n",
        "    aggregated_context_frequency = np.sum([entry['context_frequency'] for entry in entries_for_hash])\n",
        "    aggregated_word_count = np.mean([entry['word_count'] for entry in entries_for_hash])\n",
        "    aggregated_image_count = np.mean([entry['image_count'] for entry in entries_for_hash])\n",
        "    aggregated_external_link_count = np.mean([entry['external_link_count'] for entry in entries_for_hash])\n",
        "    aggregated_internal_link_count = np.mean([entry['internal_link_count'] for entry in entries_for_hash])\n",
        "\n",
        "    # tetxtual features\n",
        "    alt_texts = [entry['alt_text'] for entry in entries_for_hash]\n",
        "    most_common_alt_text = Counter(alt_texts).most_common(1)[0][0]\n",
        "\n",
        "    headlines_above_image = [entry['headline_above_image'] for entry in entries_for_hash]\n",
        "    most_common_headline = Counter(headlines_above_image).most_common(1)[0][0]\n",
        "\n",
        "    wrapped_elements = [entry['wrapped_element'] for entry in entries_for_hash]\n",
        "    most_common_wrapped_element = Counter(wrapped_elements).most_common(1)[0][0]\n",
        "\n",
        "    aggregated_data.append({\n",
        "        'hash': hash_value,\n",
        "        'alt_text': most_common_alt_text,\n",
        "        'image_title': entries_for_hash[0]['image_title'],\n",
        "        'image_caption': entries_for_hash[0]['image_caption'],\n",
        "        'width': entries_for_hash[0]['width'],\n",
        "        'height': entries_for_hash[0]['height'],\n",
        "        'file_format': entries_for_hash[0]['file_format'],\n",
        "        'file_name': entries_for_hash[0]['file_name'],\n",
        "        'contains_transparency': entries_for_hash[0]['contains_transparency'],\n",
        "        'wrapped_element': most_common_wrapped_element,\n",
        "        'semantic_context': entries_for_hash[0]['semantic_context'],\n",
        "        'headline_above_image': most_common_headline,\n",
        "        'title': entries_for_hash[0]['title'],\n",
        "        'meta_description': entries_for_hash[0]['meta_description'],\n",
        "        'top_headline': entries_for_hash[0]['top_headline'],\n",
        "        'word_count': aggregated_word_count,\n",
        "        'image_count': aggregated_image_count,\n",
        "        'context_frequency': aggregated_context_frequency,\n",
        "        'is_link': entries_for_hash[0]['is_link'],\n",
        "        'is_button': entries_for_hash[0]['is_button'],\n",
        "        'external_link_count': aggregated_external_link_count,\n",
        "        'internal_link_count': aggregated_internal_link_count,\n",
        "        'is_decorative': entries_for_hash[0]['is_decorative']\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6juL3LQcv_iB"
      },
      "source": [
        "Step 2: z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAhT1UgJwEu3"
      },
      "outputs": [],
      "source": [
        "numerical_features = ['width', 'height', 'word_count', 'image_count', 'external_link_count', 'internal_link_count', 'context_frequency']\n",
        "numerical_data = np.array([[entry.get(feature, 0) for feature in numerical_features] for entry in aggregated_data])\n",
        "scaler = StandardScaler()\n",
        "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "for i in range(len(aggregated_data)):\n",
        "    for j, feature in enumerate(numerical_features):\n",
        "        aggregated_data[i][feature] = numerical_data_scaled[i, j]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzU7YJFMwNlR"
      },
      "source": [
        "Step 3: Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEI07Zy79dl2"
      },
      "outputs": [],
      "source": [
        "def normalize_unicode(text):\n",
        "    normalized_text = unicodedata.normalize('NFKC', text)\n",
        "    cleaned_text = ''.join(c for c in normalized_text if unicodedata.category(c) != 'Cc' and unicodedata.category(c) != 'Cs')\n",
        "    return cleaned_text\n",
        "\n",
        "text_data = []\n",
        "for entry in aggregated_data:\n",
        "    alt_text = str(entry['alt_text']).encode('utf-8').decode('utf-8') if entry['alt_text'] is not None else ''\n",
        "    image_title = str(entry['image_title']).encode('utf-8').decode('utf-8') if entry['image_title'] is not None else ''\n",
        "    image_caption = str(entry['image_caption']).encode('utf-8').decode('utf-8') if entry['image_caption'] is not None else ''\n",
        "    headline_above_image = str(entry['headline_above_image']).encode('utf-8').decode('utf-8') if entry['headline_above_image'] is not None else ''\n",
        "    title = str(entry['title']).encode('utf-8').decode('utf-8') if entry['title'] is not None else ''\n",
        "    meta_description = str(entry['meta_description']).encode('utf-8').decode('utf-8') if entry['meta_description'] is not None else ''\n",
        "    top_headline = str(entry['top_headline']).encode('utf-8').decode('utf-8') if entry['top_headline'] is not None else ''\n",
        "    file_name = str(entry['file_name']).encode('utf-8').decode('utf-8') if entry['file_name'] is not None else ''\n",
        "\n",
        "    processed_texts = [\n",
        "        normalize_unicode(alt_text),\n",
        "        normalize_unicode(image_title),\n",
        "        normalize_unicode(image_caption),\n",
        "        normalize_unicode(headline_above_image),\n",
        "        normalize_unicode(title),\n",
        "        normalize_unicode(meta_description),\n",
        "        normalize_unicode(top_headline),\n",
        "        normalize_unicode(file_name)\n",
        "    ]\n",
        "    text_data.extend(processed_texts)\n",
        "\n",
        "vectorize_layer = TextVectorization(output_mode=\"tf_idf\")\n",
        "vectorize_layer.adapt(text_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwXsW1cGw0Lv"
      },
      "source": [
        "Step 4: create new dataset and one-hot encode features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT42UTsrPJdx",
        "outputId": "f9539966-4ad5-43a5-adf5-55d35c802f5c"
      },
      "outputs": [],
      "source": [
        "def extract_combined_metadata(entry):\n",
        "    image_metadata = {\n",
        "        'width': entry.get('width', 0),\n",
        "        'height': entry.get('height', 0),\n",
        "        'contains_transparency': entry.get('contains_transparency', False),\n",
        "        'is_link': entry.get('is_link', False),\n",
        "        'is_button': entry.get('is_button', False),\n",
        "        'context_frequency': entry.get('context_frequency', 0)\n",
        "    }\n",
        "    page_metadata = {\n",
        "        'word_count': entry.get('word_count', 0),\n",
        "        'image_count': entry.get('image_count', 0),\n",
        "        'external_link_count': entry.get('external_link_count', 0),\n",
        "        'internal_link_count': entry.get('internal_link_count', 0)\n",
        "    }\n",
        "    combined_metadata = {**image_metadata, **page_metadata}\n",
        "    return list(combined_metadata.values())\n",
        "\n",
        "\n",
        "file_formats = ['svg', 'png', 'jpeg', 'webp']\n",
        "file_format_mapping = {format: idx for idx, format in enumerate(file_formats)}\n",
        "\n",
        "semantic_contexts = [None, 'article', 'aside', 'footer', 'header', 'main', 'nav', 'section']\n",
        "semantic_context_mapping = {context: idx for idx, context in enumerate(semantic_contexts)}\n",
        "\n",
        "wrapped_elements = ['a', 'article', 'aside', 'div', 'figure', 'li', 'p', 'picture', 'span', 'strong']\n",
        "wrapped_element_mapping = {element: idx for idx, element in enumerate(wrapped_elements)}\n",
        "\n",
        "image_arrays = []\n",
        "metadata_arrays = []\n",
        "label_arrays = []\n",
        "for entry in aggregated_data:\n",
        "    file_format = entry['file_format']\n",
        "    if entry['file_format'] == 'svg':\n",
        "        file_format = 'png'\n",
        "    file_name = f\"{entry['hash']}.{file_format.lower()}\"\n",
        "    image = load_image(file_name)\n",
        "\n",
        "    if image:\n",
        "        if image.mode == \"P\" and \"transparency\" in image.info:\n",
        "            image = image.convert(\"RGBA\")\n",
        "        image = image.resize((image_height, image_width))\n",
        "        image_array = img_to_array(image)\n",
        "        image_array = preprocess_input(image_array)\n",
        "\n",
        "        image_arrays.append(image_array)\n",
        "        metadata = extract_combined_metadata(entry)\n",
        "\n",
        "        # One-Hot-Encoding for file_format\n",
        "        file_format_vector = [0] * len(file_formats)\n",
        "        format_index = file_format_mapping.get(entry['file_format'], -1)\n",
        "        if format_index != -1:\n",
        "            file_format_vector[format_index] = 1\n",
        "        metadata.extend(file_format_vector)\n",
        "\n",
        "        # One-Hot-Encoding for semantic_context\n",
        "        semantic_context_vector = [0] * len(semantic_contexts)\n",
        "        semantic_context_index = semantic_context_mapping.get(entry['semantic_context'], -1)\n",
        "        if semantic_context_index != -1:\n",
        "            semantic_context_vector[semantic_context_index] = 1\n",
        "        metadata.extend(semantic_context_vector)\n",
        "\n",
        "        # One-Hot-Encoding for wrapped_element\n",
        "        wrapped_element_vector = [0] * len(wrapped_elements)\n",
        "        wrapped_index = wrapped_element_mapping.get(entry['wrapped_element'], -1)\n",
        "        if wrapped_index != -1:\n",
        "            wrapped_element_vector[wrapped_index] = 1\n",
        "        metadata.extend(wrapped_element_vector)\n",
        "\n",
        "        text_features = [\n",
        "            str(entry['headline_above_image']) if entry['headline_above_image'] is not None else '',\n",
        "            str(entry['title']) if entry['title'] is not None else '',\n",
        "            str(entry['meta_description']) if entry['meta_description'] is not None else '',\n",
        "            str(entry['top_headline']) if entry['top_headline'] is not None else '',\n",
        "            str(entry['alt_text']) if entry['alt_text'] is not None else '',\n",
        "            str(entry['image_title']) if entry['image_title'] is not None else '',\n",
        "            str(entry['image_caption']) if entry['image_caption'] is not None else '',\n",
        "            str(entry['file_name']) if entry['file_name'] is not None else ''\n",
        "        ]\n",
        "\n",
        "        vectorized_text = vectorize_layer(text_features)\n",
        "        vectorized_text_flat = tf.reshape(vectorized_text, [-1])\n",
        "        metadata.extend(vectorized_text_flat.numpy().tolist())\n",
        "\n",
        "        metadata_arrays.append(metadata)\n",
        "        label_arrays.append(entry['is_decorative'])\n",
        "\n",
        "print(metadata_arrays[:1])\n",
        "\n",
        "X_final_metadata = np.array(image_arrays)\n",
        "X_metadata = np.array(metadata_arrays)\n",
        "y_labels = np.array(label_arrays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2-fiIECTvHV"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z76Vs2LNeO8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "3d9d629c-6793-43f6-faae-f6f3ffe16b66"
      },
      "outputs": [],
      "source": [
        "def MetaBlock(V, U):\n",
        "  # V image input, U metadata input\n",
        "    U_dim = U.shape[-1]\n",
        "    V_dim = V.shape[-1]\n",
        "\n",
        "    t1 = Dense(V_dim)(U)\n",
        "    t1 = BatchNormalization()(t1)\n",
        "    t1 = Reshape((1, V_dim))(t1)\n",
        "\n",
        "    t2 = Dense(V_dim)(U)\n",
        "    t2 = BatchNormalization()(t2)\n",
        "    t2 = Reshape((1, V_dim))(t2)\n",
        "\n",
        "    V_modulated = Multiply()([sigmoid(tanh(V)), t1])\n",
        "    V_modulated = Add()([V_modulated, t2])\n",
        "    return V_modulated\n",
        "\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "all_train_accuracy = []\n",
        "all_val_accuracy = []\n",
        "all_train_loss = []\n",
        "all_val_loss = []\n",
        "all_train_precision = []\n",
        "all_val_precision = []\n",
        "all_train_recall = []\n",
        "all_val_recall = []\n",
        "all_val_f1_score = []\n",
        "\n",
        "fold_no = 1\n",
        "for train_idx, val_idx in kf.split(X_images, y_labels):\n",
        "    print(f'Training on fold {fold_no}/{k_folds}...')\n",
        "\n",
        "    X_train_images, X_val_images = X_images[train_idx], X_images[val_idx]\n",
        "    X_train_metadata, X_val_metadata = X_final_metadata[train_idx], X_final_metadata[val_idx]\n",
        "    y_train, y_val = y_labels[train_idx], y_labels[val_idx]\n",
        "\n",
        "    resnet = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Image Input and Feature Extraction\n",
        "    image_input = Input(shape=(image_height, image_width, 3))\n",
        "    x = resnet(image_input)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Metadata Input and Dense Layers\n",
        "    metadata_input = Input(shape=(X_train_metadata.shape[1],))\n",
        "    y = Dense(128, activation='relu')(metadata_input)\n",
        "    y = Dropout(0.4)(y)\n",
        "    y = Dense(64, activation='relu')(y)\n",
        "\n",
        "    # Combined Features\n",
        "    modulated_features = MetaBlock(x, y)\n",
        "    modulated_features = BatchNormalization()(modulated_features)\n",
        "\n",
        "    z = Dense(64, activation='relu')(modulated_features)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Dropout(0.4)(z)\n",
        "    z = Dense(32, activation='relu')(z)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Dropout(0.4)(z)\n",
        "\n",
        "    # Output Layer\n",
        "    output = Dense(1, activation='sigmoid')(z)\n",
        "    output = Flatten()(output)\n",
        "\n",
        "    model = Model(inputs=[image_input, metadata_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(name='precision_m'), Recall(name='recall_m')])\n",
        "\n",
        "    history = model.fit(\n",
        "        [X_train_images, X_train_metadata], y_train,\n",
        "        validation_data=([X_val_images, X_val_metadata], y_val),\n",
        "        epochs=epochs, batch_size=batch_size\n",
        "    )\n",
        "    all_train_accuracy.append(history.history['accuracy'])\n",
        "    all_val_accuracy.append(history.history['val_accuracy'])\n",
        "    all_train_loss.append(history.history['loss'])\n",
        "    all_val_loss.append(history.history['val_loss'])\n",
        "    all_train_precision.append(history.history['precision_m'])\n",
        "    all_val_precision.append(history.history['val_precision_m'])\n",
        "    all_train_recall.append(history.history['recall_m'])\n",
        "    all_val_recall.append(history.history['val_recall_m'])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "all_results = {\n",
        "    'Train Accuracy': np.concatenate(all_train_accuracy),\n",
        "    'Validation Accuracy': np.concatenate(all_val_accuracy),\n",
        "    'Train Loss': np.concatenate(all_train_loss),\n",
        "    'Validation Loss': np.concatenate(all_val_loss),\n",
        "    'Train Precision': np.concatenate(all_train_precision),\n",
        "    'Validation Precision': np.concatenate(all_val_precision),\n",
        "    'Train Recall': np.concatenate(all_train_recall),\n",
        "    'Validation Recall': np.concatenate(all_val_recall),\n",
        "}\n",
        "\n",
        "print(all_results)\n",
        "\n",
        "print(f'Average accuracy over {k_folds} folds: {np.mean(val_accuracy)}')\n",
        "print(f'Average precision over {k_folds} folds: {np.mean(val_precision)}')\n",
        "print(f'Average recall over {k_folds} folds: {np.mean(val_recall)}')\n",
        "print(f'Average loss over {k_folds} folds: {np.mean(val_loss)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNP77dzRB49X0D3Iqj4wY9N"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
